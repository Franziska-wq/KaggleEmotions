{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 - Find average number of negations in each category\n",
    "**For this, I loop in each category of tweets, and test if there are negation words or prefixes or suffixes inside. I add this to a variable named ```negation_count``` that i divide by the number of tweets at the end. I created a third column that i add to the dataset**  \n",
    "\n",
    "Response time : 18s  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "negation_words = {'no', 'not', 'neither', 'never', 'no one', 'nobody', 'none', 'nor', 'nothing', 'nowhere'}\n",
    "prefixes = {'un', 'im', 'in', 'il', 'ir', 'dis'}\n",
    "suffix = 'less'\n",
    "\n",
    "def find_average_number_of_negation_in_each_category(file_path, file_name):\n",
    "    average_number_of_negation_in_each_category = []\n",
    "    df = pd.read_csv(\"{}/{}.csv\".format(file_path, file_name))\n",
    "    for tweets in df[\"Concatenated_Tweets\"]:\n",
    "        negation_count = 0\n",
    "        separated_tweets = tweets.replace(\"[\", \"\").replace(\"]\", \"\").split(',')\n",
    "        for tweet in separated_tweets:\n",
    "            tokens = nltk.word_tokenize(tweet)\n",
    "            negation_count += sum(1 for token in tokens if token in negation_words)\n",
    "            negation_count += sum(1 for token in tokens if any(token.startswith(prefix) for prefix in prefixes))\n",
    "            negation_count += sum(1 for token in tokens if token.endswith(suffix))\n",
    "        average_number_of_negation_in_each_category.append(round(negation_count/len(separated_tweets), 3))\n",
    "    df[\"Average_Number_Of_Negation\"]=average_number_of_negation_in_each_category\n",
    "    return df\n",
    "            \n",
    "    \n",
    "\n",
    "test_with_negation = find_average_number_of_negation_in_each_category('categories','test')\n",
    "train_with_negation = find_average_number_of_negation_in_each_category('categories','train')\n",
    "val_with_negation = find_average_number_of_negation_in_each_category('categories','val')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 - Training a SVM classifier (with n-gram TF-IDF vecotrization)\n",
    "**I vectorized the features of the train set and the test set and created the model ```svm_classifier``` and fitted it with train set. Then, I predicted the results with the test set and computed all f1-scores and displayed them by categories**  \n",
    "\n",
    "Response time : 11m  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported\n",
      "Vectorization done\n",
      "Blank model created\n",
      "Model trained\n",
      "Prediction done\n",
      "[0.43309002 0.49562682 0.68173706 0.21649485 0.63790447 0.10958904]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def read_txt_data_and_split(file_path, file_name):\n",
    "    df = pd.read_csv(\"{}/{}.txt\".format(file_path, file_name), sep=\";\", header=None)\n",
    "    df.columns=[\"Tweet\", \"Emotion\"]\n",
    "    return df[\"Tweet\"], df[\"Emotion\"]\n",
    "\n",
    "X_train, y_train = read_txt_data_and_split(\"data\", \"train\")\n",
    "X_test, y_test = read_txt_data_and_split(\"data\", \"test\")\n",
    "print(\"Data imported\")\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(2,3), analyzer='char', max_features=500)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "print(\"Vectorization done\")\n",
    "\n",
    "svm_classifier = SVC()\n",
    "print(\"Blank model created\")\n",
    "\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "print(\"Model trained\")\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "print(\"Prediction done\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for anger: 0.4330900243309002\n",
      "F1-score for fear: 0.49562682215743437\n",
      "F1-score for joy: 0.6817370612730518\n",
      "F1-score for love: 0.21649484536082475\n",
      "F1-score for sadness: 0.6379044684129429\n",
      "F1-score for surprise: 0.10958904109589043\n"
     ]
    }
   ],
   "source": [
    "category_names = svm_classifier.classes_\n",
    "\n",
    "for category, score in zip(category_names, f1):\n",
    "    print(f\"F1-score for {category}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26a650b9244880cda9b3c29eedb27f415fa4f6f8549b7618a68bcac8b230ec01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
