{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4fee3c3",
   "metadata": {},
   "source": [
    "# Exc 2\n",
    "\n",
    "Inspired from\n",
    "https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018d8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_and_variables as fs\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d3e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes [key: sentences] for test were successfully created and stored as .csv\n",
      "Dataframes [key: sentences] for val were successfully created and stored as .csv\n",
      "Dataframes [key: sentences] for train were successfully created and stored as .csv\n",
      "Dataframes [key: sentences] for complete were successfully created and stored as .csv\n"
     ]
    }
   ],
   "source": [
    "def concat_categories_to_file(file_path, file_name, export_path):\n",
    "    data = pd.read_csv(\"{}/{}.txt\".format(file_path,file_name),sep=';')\n",
    "    tweets = data.iloc[:, 0]\n",
    "    categories = data.iloc[:, 1]\n",
    "    \n",
    "    category_tweets = {}\n",
    "    for category, tweet in zip(categories, tweets):\n",
    "        if category not in category_tweets:\n",
    "            category_tweets[category] = []\n",
    "        category_tweets[category].append(tweet)\n",
    "\n",
    "    result = pd.DataFrame(category_tweets.items(),columns=['Category', 'Concatenated_Tweets'])\n",
    "    result.to_csv('{}/{}.csv'.format(export_path,file_name), index=False, encoding='utf-8')\n",
    "    print('Dataframes [key: sentences] for {} were successfully created and stored as .csv'.format(file_name))\n",
    "    return category_tweets\n",
    "\n",
    "for file in ['test','val','train','complete']:\n",
    "    if file == 'complete':\n",
    "        dataframe_categories = concat_categories_to_file('data',file,'categories')\n",
    "    else:\n",
    "        concat_categories_to_file('data',file,'categories')\n",
    "\n",
    "dataframe_categories = dict(sorted(dataframe_categories.items()))\n",
    "categories = dataframe_categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3424340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Stemming and remove Stopwords\n",
    "def preprocess(sentences: list):\n",
    "    cleaned = []\n",
    "    \n",
    "    for sentence in sentences: \n",
    "        stop_words = list(set(stopwords.words('english')))\n",
    "        stop_words.extend(['im', 'ive','dont','cant'])\n",
    "        stemmer = PorterStemmer()\n",
    "    \n",
    "        word_tokens = word_tokenize(sentence)\n",
    "        cleaned.extend([stemmer.stem(w) for w in word_tokens if not w.lower() in stop_words])\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# Returns the words of a sentence\n",
    "def sent_to_words(sentences: list):\n",
    "        return [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81330511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lda(category: str, data: list, shoud_preprocess: bool, num_topis: int, num_words: int):\n",
    "    \n",
    "    data_words = []\n",
    "\n",
    "    if not shoud_preprocess:\n",
    "        data_words = list(sent_to_words(data))\n",
    "\n",
    "    else:\n",
    "        data_words.append(preprocess(data))\n",
    "    \n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "    \n",
    "    # Create Corpus\n",
    "    texts = data_words\n",
    "    \n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Build LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=id2word,\n",
    "                                           num_topics=num_topics)\n",
    "\n",
    "    # Print the Keyword with the specified number of words\n",
    "    print(category + \":\")\n",
    "    keywords = lda_model.print_topics(num_words=num_words)\n",
    "    pprint(keywords)\n",
    "    file_path = fs.result_path + 'lda/lda_ana_' + category + '.txt'\n",
    "    fs.write_to_file(file_path=file_path, \n",
    "                     content=str(keywords), new=True)\n",
    "    print('File for \"' + category +'\" successfully created at: ' + file_path)\n",
    "    return id2word, corpus, lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c810a27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger:\n",
      "[(0, '0.055*\"i\" + 0.036*\"the\" + 0.031*\"feel\" + 0.029*\"to\"'),\n",
      " (1, '0.094*\"i\" + 0.032*\"feel\" + 0.029*\"and\" + 0.024*\"to\"'),\n",
      " (2, '0.053*\"i\" + 0.028*\"feel\" + 0.022*\"to\" + 0.021*\"a\"')]\n",
      "File for \"anger\" successfully created at: ./results/lda/lda_ana_anger.txt\n",
      "fear:\n",
      "[(0, '0.039*\"i\" + 0.026*\"and\" + 0.026*\"the\" + 0.022*\"feel\"'),\n",
      " (1, '0.076*\"i\" + 0.032*\"feel\" + 0.028*\"and\" + 0.027*\"the\"'),\n",
      " (2, '0.088*\"i\" + 0.036*\"to\" + 0.030*\"feel\" + 0.026*\"and\"')]\n",
      "File for \"fear\" successfully created at: ./results/lda/lda_ana_fear.txt\n",
      "joy:\n",
      "[(0, '0.085*\"i\" + 0.036*\"feel\" + 0.028*\"the\" + 0.026*\"and\"'),\n",
      " (1, '0.071*\"i\" + 0.041*\"to\" + 0.031*\"feel\" + 0.028*\"the\"'),\n",
      " (2, '0.066*\"i\" + 0.042*\"and\" + 0.040*\"feel\" + 0.025*\"to\"')]\n",
      "File for \"joy\" successfully created at: ./results/lda/lda_ana_joy.txt\n",
      "love:\n",
      "[(0, '0.052*\"i\" + 0.034*\"to\" + 0.031*\"feel\" + 0.022*\"and\"'),\n",
      " (1, '0.079*\"i\" + 0.040*\"feel\" + 0.028*\"the\" + 0.024*\"a\"'),\n",
      " (2, '0.070*\"i\" + 0.044*\"and\" + 0.027*\"to\" + 0.026*\"the\"')]\n",
      "File for \"love\" successfully created at: ./results/lda/lda_ana_love.txt\n",
      "sadness:\n",
      "[(0, '0.092*\"i\" + 0.033*\"and\" + 0.030*\"feel\" + 0.027*\"to\"'),\n",
      " (1, '0.071*\"i\" + 0.036*\"to\" + 0.031*\"the\" + 0.031*\"feel\"'),\n",
      " (2, '0.083*\"i\" + 0.042*\"feel\" + 0.035*\"and\" + 0.021*\"feeling\"')]\n",
      "File for \"sadness\" successfully created at: ./results/lda/lda_ana_sadness.txt\n",
      "surprise:\n",
      "[(0, '0.027*\"i\" + 0.024*\"the\" + 0.020*\"and\" + 0.016*\"feel\"'),\n",
      " (1, '0.055*\"i\" + 0.035*\"and\" + 0.029*\"feeling\" + 0.026*\"the\"'),\n",
      " (2, '0.089*\"i\" + 0.038*\"feel\" + 0.025*\"the\" + 0.024*\"to\"')]\n",
      "File for \"surprise\" successfully created at: ./results/lda/lda_ana_surprise.txt\n"
     ]
    }
   ],
   "source": [
    "num_topics = 3\n",
    "num_words = 4\n",
    "lda_dict = dict.fromkeys(dataframe_categories.keys(), [])\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "index = 0\n",
    "for category in categories:    \n",
    "    # Perform LDA for the current topic\n",
    "    lda_dict[category] = perform_lda(category=category, \n",
    "                                             data=dataframe_categories[category], shoud_preprocess=False, \n",
    "                                             num_topis=num_topics, num_words=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5bb40",
   "metadata": {},
   "source": [
    "# Exc 3\n",
    "\n",
    "Inspired from https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d495223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pyLDAvis to visualize LDA\n",
    "def visualize_lda(category: str, id2word, corpus, lda_model, num_topics: int):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(fs.result_path + 'lda/', exist_ok=True)\n",
    "    \n",
    "    filename = fs.result_path + 'lda/ldavis_prepared_' + category + '_' +  str(num_topics)\n",
    "    LDAvis_data_filepath = os.path.join(filename)\n",
    "    \n",
    "    ### this is a bit time consuming - make the if statement True\n",
    "    ### if you want to execute visualization prep yourself\n",
    "    if 1 == 1:\n",
    "        LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, n_jobs=1)\n",
    "        \n",
    "        with open(LDAvis_data_filepath, 'wb') as f:\n",
    "            pickle.dump(LDAvis_prepared, f)\n",
    "    \n",
    "    # load the pre-prepared pyLDAvis data from disk\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "    \n",
    "    html_filename = filename + '.html'\n",
    "    pyLDAvis.save_html(LDAvis_prepared, html_filename)\n",
    "    print('File for \"' + category + '\" successfully created at: ' + html_filename)\n",
    "    return LDAvis_prepared, html_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e29c4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for \"anger\" successfully created at: ./results/lda/ldavis_prepared_anger_3.html\n",
      "File for \"fear\" successfully created at: ./results/lda/ldavis_prepared_fear_3.html\n",
      "File for \"joy\" successfully created at: ./results/lda/ldavis_prepared_joy_3.html\n",
      "File for \"love\" successfully created at: ./results/lda/ldavis_prepared_love_3.html\n",
      "File for \"sadness\" successfully created at: ./results/lda/ldavis_prepared_sadness_3.html\n",
      "File for \"surprise\" successfully created at: ./results/lda/ldavis_prepared_surprise_3.html\n"
     ]
    }
   ],
   "source": [
    "for category in categories:    \n",
    "    # Create visualisation\n",
    "    prepared_data, html_filename = visualize_lda(category=category, id2word=lda_dict[category][0], \n",
    "                                                 corpus=lda_dict[category][1], \n",
    "                                                 lda_model=lda_dict[category][2], \n",
    "                                                 num_topics=num_topics)\n",
    "    \n",
    "    # Display the visualization directly in the notebook\n",
    "    #display(pyLDAvis.display(prepared_data))\n",
    "    \n",
    "    # Open the HTML files in a web browser (if running on windows: replace \"open \" with \"start \")\n",
    "    #os.system(\"open \" + html_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8533f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
