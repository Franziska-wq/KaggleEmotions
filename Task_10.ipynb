{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the quality of data augmentation on classification performance. For this purpose, consider the classes with small sample size (categories Disgust and Anticipation), identify from Kaggle or elsewhere labeled dataset of the same categories And add it to these two categories. Test the SVM classifier in Task 7 and discuss whether the overall performance can be increased or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset doesn't contain categories Disgust and Anticipation. So here I use surprise and love. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataset is not yet preprocessed. So we have to remove stopwords, and perform stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "\n",
    "def preprocess_to_sentence(sentence):\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    stop_words.extend(['im', 'ive', 'id', 'dont','cant', 'wont'])\n",
    "    words = word_tokenize(sentence)\n",
    "    words = [word.lower() for word in words if word not in string.punctuation and word not in stop_words]\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    preprocessed_sentence = ' '.join(words)\n",
    "    \n",
    "    return preprocessed_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of dataset, we select 100 samples that in the categories love and surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprise</td>\n",
       "      <td>'feel like need emphas impress color'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>'feel love chang modern mother'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>'know feel like legitem like someon somehow g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprise</td>\n",
       "      <td>happi star war day ohhhh ... i get may 4th lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>curious_jo ... i like freedom enigma give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>surprise</td>\n",
       "      <td>warn tweet rid bike dangero waaaaaaa crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>love</td>\n",
       "      <td>'much lighter feel extrem passion life ye'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>surprise</td>\n",
       "      <td>'feel impress happi thing like use'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>surprise</td>\n",
       "      <td>today interest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>love</td>\n",
       "      <td>just get home work ... final</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                              tweet\n",
       "0    surprise              'feel like need emphas impress color'\n",
       "1        love                    'feel love chang modern mother'\n",
       "2        love   'know feel like legitem like someon somehow g...\n",
       "3    surprise  happi star war day ohhhh ... i get may 4th lov...\n",
       "4        love          curious_jo ... i like freedom enigma give\n",
       "..        ...                                                ...\n",
       "195  surprise         warn tweet rid bike dangero waaaaaaa crash\n",
       "196      love         'much lighter feel extrem passion life ye'\n",
       "197  surprise                'feel impress happi thing like use'\n",
       "198  surprise                                 today interest ...\n",
       "199      love                       just get home work ... final\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_sample_data_for_categories(file_name,categories_to_extract):\n",
    "    data = pd.read_csv('categories/{}.csv'.format(file_name))\n",
    "    sample_size = 100 / len(categories_to_extract)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for category in categories_to_extract:\n",
    "        index = data[data['Category'] == category].index[0]\n",
    "        tweets = data['Concatenated_Tweets'][index].split(',')\n",
    "        if len(tweets) >= int(sample_size):\n",
    "            sampled_tweets = random.sample(tweets, int(sample_size))\n",
    "        else:\n",
    "            sampled_tweets = tweets\n",
    "        \n",
    "        for tweet in sampled_tweets:\n",
    "            df = pd.concat([df, pd.DataFrame([{'category': category, 'tweet': tweet}])])\n",
    "    return df\n",
    "\n",
    "def get_sample_data_for_categories_addition(categories_to_extract):\n",
    "    data = pd.read_csv('data/{}.csv'.format('text_emotion'))\n",
    "    data['pre_process'] = data['content'].apply(preprocess_to_sentence)\n",
    "    data = data.dropna(subset=['pre_process'])\n",
    "    sample_size = 100\n",
    "    sampled_data = data[data['sentiment'].isin(categories_to_extract)].sample(n=sample_size)\n",
    "    selected_columns = sampled_data[['sentiment', 'pre_process']]\n",
    "\n",
    "    selected_columns = selected_columns.rename(columns={'sentiment': 'category', 'pre_process': 'tweet'})\n",
    "    return selected_columns\n",
    "        \n",
    "categories_to_extract = ['love', 'surprise']\n",
    "sample_data = get_sample_data_for_categories('complete_preprocessed',categories_to_extract)\n",
    "sample_data_addition = get_sample_data_for_categories_addition(categories_to_extract)\n",
    "\n",
    "\n",
    "data = pd.concat([sample_data, sample_data_addition], ignore_index=True)\n",
    "shuffled_df = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizedd the features and split the dataset in to training and testing set. Then, we created svm model to fitted it. The result will be used to calculate the f1-score and compare it with the result of the Task 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "              precision    recall  f1-score  support\n",
      "love           0.533333  1.000000  0.695652    16.00\n",
      "surprise       1.000000  0.416667  0.588235    24.00\n",
      "accuracy       0.650000  0.650000  0.650000     0.65\n",
      "macro avg      0.766667  0.708333  0.641944    40.00\n",
      "weighted avg   0.813333  0.650000  0.631202    40.00\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "x = tfidf_vectorizer.fit_transform(data['tweet'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['category'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report.to_csv('results/classification_report.csv', index=True)\n",
    "print(df_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to task 7, we can see that the F1 score has improved.<br>\n",
    "F1 score before the data augmentation:<br>\n",
    "F1-score for surprise: 0.23684<br>\n",
    "F1-score for love: 0.26794<br>\n",
    "\n",
    "F1 score after the data augmentation:<br>\n",
    "F1-score for surprise: 0.588235<br>\n",
    "F1-score for love: 0.695652<br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
