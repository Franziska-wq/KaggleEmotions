{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to the quality of data augmentation on classification performance. For this purpose, consider the classes with small sample size (categories Disgust and Anticipation), identify from Kaggle or elsewhere labeled dataset of the same categories And add it to these two categories. Test the SVM classifier in 6) and discuss whether the overall performance can be increased or not. (Anh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset doesnt contain categories Disgust and Anticipation. So here I use love and sadness. Task 6 does not classify anything. Do it mean task 7 ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>'ive lived my life trying so hard to be accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>'im feeling pretty homesick this week but i s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>'i could clearly feel my adomen muscles contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@misssammibaby why are you sad?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadness</td>\n",
       "      <td>R.i.p. to my lil sis's cousins babyfather Jimm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>sadness</td>\n",
       "      <td>i dont wanna miss the laker game tonight! i'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>sadness</td>\n",
       "      <td>'i feel like that enables her rotten ass even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>love</td>\n",
       "      <td>'i really am a hard worker and feel quite loy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Approaching the weekend quite quickly and so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Stupid shopping bags left a red mark on my arm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                              tweet\n",
       "0       love   'ive lived my life trying so hard to be accep...\n",
       "1    sadness   'im feeling pretty homesick this week but i s...\n",
       "2    sadness   'i could clearly feel my adomen muscles contr...\n",
       "3    sadness                    @misssammibaby why are you sad?\n",
       "4    sadness  R.i.p. to my lil sis's cousins babyfather Jimm...\n",
       "..       ...                                                ...\n",
       "195  sadness  i dont wanna miss the laker game tonight! i'm ...\n",
       "196  sadness   'i feel like that enables her rotten ass even...\n",
       "197     love   'i really am a hard worker and feel quite loy...\n",
       "198  sadness  Approaching the weekend quite quickly and so m...\n",
       "199  sadness     Stupid shopping bags left a red mark on my arm\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_sample_data_for_categories(file_name,categories_to_extract):\n",
    "    data = pd.read_csv('categories/{}.csv'.format(file_name))\n",
    "    sample_size = 100 / len(categories_to_extract)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for category in categories_to_extract:\n",
    "        index = data[data['Category'] == category].index[0]\n",
    "        tweets = data['Concatenated_Tweets'][index].split(',')\n",
    "        if len(tweets) >= int(sample_size):\n",
    "            sampled_tweets = random.sample(tweets, int(sample_size))\n",
    "        else:\n",
    "            sampled_tweets = tweets\n",
    "        \n",
    "        for tweet in sampled_tweets:\n",
    "            df = pd.concat([df, pd.DataFrame([{'category': category, 'tweet': tweet}])])\n",
    "    return df\n",
    "\n",
    "def get_sample_data_for_categories_addition(categories_to_extract):\n",
    "    data = pd.read_csv('data/{}.csv'.format('text_emotion'))\n",
    "    sample_size = 100\n",
    "    sampled_data = data[data['sentiment'].isin(categories_to_extract)].sample(n=sample_size)\n",
    "    selected_columns = sampled_data[['sentiment', 'content']]\n",
    "    selected_columns = selected_columns.rename(columns={'sentiment': 'category', 'content': 'tweet'})\n",
    "    return selected_columns\n",
    "        \n",
    "categories_to_extract = ['sadness', 'love']\n",
    "sample_data = get_sample_data_for_categories('complete',categories_to_extract)\n",
    "sample_data_addition = get_sample_data_for_categories_addition(categories_to_extract)\n",
    "\n",
    "data = pd.concat([sample_data, sample_data_addition], ignore_index=True)\n",
    "shuffled_df = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675\n",
      "              precision    recall  f1-score  support\n",
      "love           0.857143  0.333333  0.480000   18.000\n",
      "sadness        0.636364  0.954545  0.763636   22.000\n",
      "accuracy       0.675000  0.675000  0.675000    0.675\n",
      "macro avg      0.746753  0.643939  0.621818   40.000\n",
      "weighted avg   0.735714  0.675000  0.636000   40.000\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "x = tfidf_vectorizer.fit_transform(data['tweet'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['category'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report.to_csv('report/classification_report.csv', index=True)\n",
    "print(df_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
